{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nitys\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Произведем импорт необходимых библиотек\n",
    "\n",
    "# Стандартныен библиотеки для работы с DF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Библиотека для поиска сочетаний (регуляров) \n",
    "import re\n",
    "\n",
    "# Библиотеки для парсинга\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Библиотека для кодирования \n",
    "import category_encoders as ce\n",
    "\n",
    "# Библиотеки для визуализации\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Импорт модуля для предварительной обработки данных\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Используется для подсчета времени обучения в разделе \n",
    "# \"Модель машинного обучения\"\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "# Библиотека и методы для определения эмоционального настроя текста\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение DF\n",
    "hotels_t = pd.read_csv('data/hotels_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 128935 entries, 0 to 128934\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   hotel_address                               128935 non-null  object \n",
      " 1   additional_number_of_scoring                128935 non-null  int64  \n",
      " 2   review_date                                 128935 non-null  object \n",
      " 3   average_score                               128935 non-null  float64\n",
      " 4   hotel_name                                  128935 non-null  object \n",
      " 5   reviewer_nationality                        128935 non-null  object \n",
      " 6   negative_review                             128935 non-null  object \n",
      " 7   review_total_negative_word_counts           128935 non-null  int64  \n",
      " 8   total_number_of_reviews                     128935 non-null  int64  \n",
      " 9   positive_review                             128935 non-null  object \n",
      " 10  review_total_positive_word_counts           128935 non-null  int64  \n",
      " 11  total_number_of_reviews_reviewer_has_given  128935 non-null  int64  \n",
      " 12  tags                                        128935 non-null  object \n",
      " 13  days_since_review                           128935 non-null  object \n",
      " 14  lat                                         128115 non-null  float64\n",
      " 15  lng                                         128115 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(8)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Проверка данных\n",
    "hotels_t.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются пропуски по lat и lng. Ручной метод, примененный изначально применять не будем. \n",
    "Пропишем медианную по стране. \n",
    "Для начала сделаем преобразование признаков, создавая признак страны.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропишем функцию для извлечения страны из признака адреса отеля\n",
    "def country_extract(string):\n",
    "    country = list(string.split(' '))[-1]\n",
    "    return country\n",
    "\n",
    "# Создадим новый признак страны отеля, применив функцию к адресу\n",
    "hotels_t['country'] = hotels_t['hotel_address'].apply(country_extract)\n",
    "\n",
    "# По результату получили одно из значений 'Kingdom', \n",
    "# Напишем функцию, дающую полное название страны\n",
    "hotels_t['country'] = hotels_t['country'].apply(\n",
    "    lambda x: 'United Kingdom' if x == 'Kingdom' else x\n",
    "    )\n",
    "\n",
    "# Удалим признак адреса, он для модели не пригоден \n",
    "hotels_t = hotels_t.drop('hotel_address', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitys\\AppData\\Local\\Temp\\ipykernel_141852\\4061079087.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  result = data_lat.loc[f'{col_country}'][0]\n",
      "C:\\Users\\nitys\\AppData\\Local\\Temp\\ipykernel_141852\\4061079087.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  result = data_lng.loc[f'{col_country}'][0]\n"
     ]
    }
   ],
   "source": [
    "# Создание DF с списком стран и средним значением широты\n",
    "data_lat = pd.DataFrame(\n",
    "    hotels_t.groupby('country')['lat'].mean())\n",
    "\n",
    "# Создание DF с списком стран и средним значением долготы\n",
    "data_lng = pd.DataFrame(\n",
    "    hotels_t.groupby('country')['lng'].mean())\n",
    "\n",
    "# Заполним пропуски словами-маркерами, по ним будем перезаполнять\n",
    "hotels_t['lat'] = hotels_t['lat'].fillna('toreplacelat')\n",
    "hotels_t['lng'] = hotels_t['lng'].fillna('toreplacelng')\n",
    "\n",
    "# Переименуем оригинальные названия признаков \n",
    "# В дальнейшем их удалим, после создания новых\n",
    "hotels_t = hotels_t.rename(columns={'lat': 'lat_orig', 'lng': 'lng_orig'})\n",
    "\n",
    "# Функция заполнения пропусков по \"маркерам\" - долгота\n",
    "# Если слово маркер - заменяем средним по стране, \n",
    "# Если признак заполнен, оставляем его значение\n",
    "def lat_filling(col_country, col_lat):\n",
    "    if col_lat == 'toreplacelat':\n",
    "        result = data_lat.loc[f'{col_country}'][0]\n",
    "    else:\n",
    "        result = col_lat\n",
    "    return result\n",
    "\n",
    "# Создание признака долготы\n",
    "hotels_t['lat'] = hotels_t.apply(\n",
    "    lambda x: lat_filling(x.country, x.lat_orig), axis=1\n",
    "    )\n",
    "\n",
    "# Функция заполнения пропусков по \"маркерам\" - широта\n",
    "# Если слово маркер - заменяем средним по стране, \n",
    "# Если признак заполнен, оставляем его значение\n",
    "def lng_filling(col_country, col_lng):\n",
    "    if col_lng == 'toreplacelng':\n",
    "        result = data_lng.loc[f'{col_country}'][0]\n",
    "    else:\n",
    "        result = col_lng\n",
    "    return result\n",
    "\n",
    "# Создание признака широты\n",
    "hotels_t['lng'] = hotels_t.apply(\n",
    "    lambda x: lng_filling(x.country, x.lng_orig), axis=1\n",
    "    )\n",
    "\n",
    "# Удаляем ненужные признаки, в которых есть пропуски\n",
    "hotels_t = hotels_t.drop(['lat_orig', 'lng_orig'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски заполнены, вернемся к исходной последовательности преобразования DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем чтение DF\n",
    "url='https://drive.google.com/file/d/1ATDWtM5RP-OtiFLUuePr5VGzcP3Cpdtx/view?usp=drive_link'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "top_50_world_df = pd.read_csv(url, encoding='latin-1')\n",
    "\n",
    "# Пустой список, куда занесем отдельные слова из названий отелей\n",
    "top_50_world_list = []\n",
    "\n",
    "# Функция для извлечения слов из названий отелей\n",
    "def top_50_name_extract(name):\n",
    "    words = str(name).split(' ')\n",
    "    for word in words:\n",
    "        top_50_world_list.append(word.lower())\n",
    "\n",
    "# Применим функцию    \n",
    "top_50_world_df['Name'].apply(top_50_name_extract)\n",
    "\n",
    "# Преобразуем список в множество\n",
    "top_50_world_set = set(top_50_world_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для парсинга сайта, маскируемся под браузер для обхода блокировки\n",
    "def get_page_contents(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36',\n",
    "    'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    page = requests.get(url, headers=headers)\n",
    "    return BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Адрес интересующей нас страницы\n",
    "url = 'https://www.tripadvisor.com/TravelersChoice-Hotels-cTop-g4.html'\n",
    "\n",
    "# Создание объект beatiful soup\n",
    "soup = get_page_contents(url)\n",
    "\n",
    "# Создание предобработанного списка, в элементах которого будут \n",
    "# содержатся названия отелей\n",
    "top_25_dirty_list = str(soup).split('</h2')\n",
    "\n",
    "# Счетчик итераций (в первом элементе в отличии от всех остальных элементов \n",
    "# отличается регулярное выражения для выборки названия отеля)\n",
    "counter = 0\n",
    "\n",
    "# Пустой список, будем наполнять названиями отелей\n",
    "top_25_tripadv = []\n",
    "\n",
    "# Циклом вычленяем названия отелей из предообработанного списка \n",
    "for elem in top_25_dirty_list:\n",
    "    \n",
    "    # Обработчик исключений, для успешного выполнения цикла\n",
    "    try:\n",
    "        if counter == 0:\n",
    "            name = re.search('eIegw\">(.*)', str(elem))\n",
    "        else:\n",
    "            name = re.search('rRtyp\">(.*)', str(elem))\n",
    "        name = name.group(1)\n",
    "        top_25_tripadv.append(name)\n",
    "    except:\n",
    "        continue\n",
    "    counter += 1\n",
    "    \n",
    "# Пустой список, куда занесем отдельные слова из названий отелей\n",
    "top_25_europe_list = []\n",
    "\n",
    "# Циклом вычленяем отдельные слова из названий отелей \n",
    "for name in top_25_tripadv:\n",
    "    \n",
    "    words = name.split(' ')\n",
    "    for word in words:\n",
    "        top_25_europe_list.append(word.lower())\n",
    "\n",
    "# Преобразуем список в множество\n",
    "top_25_europe_set = set(top_25_europe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ссылка на сформированный файл\n",
    "url='https://drive.google.com/file/d/1yf85a0arfHVMmU3jqOpua7Ov0FtYjpTa/view?usp=drive_link'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "# Создание DF из файла\n",
    "chain_hotels = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Список названий отелей из DF\n",
    "chain_hotels_list_orig = list(chain_hotels['Managed brands'])\n",
    "\n",
    "# Пустой список, куда занесем отдельные слова из названий отелей\n",
    "chain_hotels_list = []\n",
    "\n",
    "# Вычленим циклом слова из названий отелей и занесем их с список выше\n",
    "for name in chain_hotels_list_orig:\n",
    "    # Обработчик исключений требуется для избежания вызова ошибок при обработки \n",
    "    # (имеются числовые данные и символы в результате преобразования)\n",
    "    try:\n",
    "        words = list(name.split(' '))\n",
    "        for word in words: \n",
    "            chain_hotels_list.append(word.lower())\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Преобразуем список в множество\n",
    "chain_hotels_set = set(chain_hotels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим множества \n",
    "\n",
    "key_words_top = top_50_world_set.union(top_25_europe_set)\n",
    "key_words_top = key_words_top.union(chain_hotels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим список слов к удалению из множества\n",
    "# Данные слова/артикли могут быть общими как для брендового отеля, \n",
    "# так и для обычного, так же, внесем названия столиц, представленных стран\n",
    "excluding_words = {'hotel', 'spa', 'resort', 'inn', 'ink', 'apartment', \n",
    "                   'apart', 'villa', 'hostel', 'motel', 'bed', 'breakfast', \n",
    "                   'b&b', 'palace', 'park',\n",
    "                   \n",
    "                   'the', 'by', 'a', 'an', 'of', 'in', 'la', 'les', 'le',\n",
    "                   \n",
    "                   'london', 'paris', 'amsterdam', 'madrid', 'barcelona', \n",
    "                   'vienna', 'rome'\n",
    "                   }\n",
    "\n",
    "key_words = key_words_top.difference(excluding_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция проверки вхождения множества слов из названия отеля в \n",
    "# ранее созданное множество слов характерных для сетевых или топовых отелей\n",
    "# Функция возвращает 1 - если есть вхождение, в противном случае - 0.\n",
    "def hotel_name_top(name):\n",
    "    words = name.split(' ')\n",
    "    name_set = set()\n",
    "    \n",
    "    for word in words:\n",
    "        name_set.add(word.lower())\n",
    "    \n",
    "    if name_set.intersection(key_words):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Создание нового бинарного признака является ли отель сетевым/топовым\n",
    "hotels_t['top'] = hotels_t['hotel_name'].apply(hotel_name_top)\n",
    "\n",
    "# Удалим признак названия отеля\n",
    "hotels_t = hotels_t.drop(['hotel_name'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем тип признака в datetime, воспользуемся аксессором по месяцу\n",
    "hotels_t['review_date'] = pd.to_datetime(hotels_t['review_date'])\n",
    "hotels_t['review_date'] = hotels_t['review_date'].dt.month\n",
    "hotels_t['review_date'] = hotels_t['review_date'].astype('int64')\n",
    "\n",
    "# Функция преобразования месяца в сезон\n",
    "def season_detect(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    if month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    if month in [9, 10, 11]:\n",
    "        return 'autumn'\n",
    "\n",
    "# Создание нового признака сезона отзыва постояльца\n",
    "hotels_t['review_season'] = hotels_t['review_date'].apply(season_detect)\n",
    "\n",
    "# Удалим уже ненужный признак\n",
    "hotels_t = hotels_t.drop(['review_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция преобразования признака в категориальный\n",
    "def days_convert(feature):\n",
    "    days = int(feature.split(' ')[0])\n",
    "    if 0 <= days < 100:\n",
    "        return '0-100' \n",
    "    if 100 <= days < 200:\n",
    "        return '100-200' \n",
    "    if 200 <= days < 300:\n",
    "        return '100-300' \n",
    "    if 300 <= days < 400:\n",
    "        return '300-400' \n",
    "    if 400 <= days < 500:\n",
    "        return '400-500' \n",
    "    if 500 <= days < 600:\n",
    "        return '500-600' \n",
    "    if 600 <= days:\n",
    "        return '<_600' \n",
    "\n",
    "# Создание нового категориального признака времени, прошедшего с обзора\n",
    "hotels_t['days_since_review'] = hotels_t['days_since_review'].apply(\n",
    "    days_convert\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработаем исходный признак, удалив лишние пробелы в строковых данных\n",
    "hotels_t['reviewer_nationality'] = hotels_t['reviewer_nationality'].apply(\n",
    "    lambda x: x.strip()\n",
    "    )\n",
    "\n",
    "# Функция для сравнения значений двух признаков\n",
    "# Возвращает 1, если совпадение, в противном случае 0\n",
    "def compare_country(col_1, col_2):\n",
    "    if str(col_1) == str(col_2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Создаем новый признак, свидетельствующий о равности гражданства и страны отеля\n",
    "hotels_t['same_country'] = hotels_t.apply(\n",
    "    lambda x: compare_country(x.reviewer_nationality, x.country), axis = 1\n",
    "    ) \n",
    "\n",
    "# Удаляем признак гражданства постояльца\n",
    "hotels_t = hotels_t.drop(['reviewer_nationality'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Создадим новые признаки - копии существующих и с ними будем работать\\nhotels_t[[\\'positive_rev_to_vader\\', \\'negative_rev_to_vader\\']] =     hotels_t[[\\'positive_review\\', \\'negative_review\\']].copy()\\n\\n# Функция для подмены позитивных слов в негативных отзывах\\ndef negative_turnover(elem):\\n    neg_to_pos_list = [\\'leaving\\', \\'no negative\\', \\'nothing\\']\\n    for word in neg_to_pos_list:\\n        elem = elem.lower()\\n        elem = elem.replace(f\\'{word}\\', \\'positive\\')\\n    return elem\\n\\n# Функция для подмены негативных слов в позитивных отзывах\\ndef positive_turnover(elem):\\n    pos_to_neg_list = [\\'nothing\\', \\'no positive\\']\\n    for word in pos_to_neg_list:\\n        elem = elem.lower().replace(f\\'{word}\\', \\'negative\\')\\n    return elem\\n    \\n# Применений функций к признакам\\nhotels_t[\\'negative_rev_to_vader\\'] =     hotels_t[\\'negative_rev_to_vader\\'].apply(negative_turnover)\\n\\n\\nhotels_t[\\'positive_rev_to_vader\\'] =     hotels_t[\\'positive_rev_to_vader\\'].apply(positive_turnover)\\n\\n# \"Склейка\" позитивного и негативного отзывов в единый (для извлечений compound)\\nhotels_t[\\'to_vader\\'] =     hotels_t[\\'positive_rev_to_vader\\'] + hotels_t[\\'negative_rev_to_vader\\'] \\n\\n# Функция для получения коэффициента общего значения \\n# по словам суммарного отзыва\\ndef vader_analitics(review):\\n    sid = SentimentIntensityAnalyzer()\\n    ss = sid.polarity_scores(review)\\n    return ss[\\'compound\\']\\n\\n# Создание нового признака \\nhotels_t[\\'vader_score\\'] = hotels_t[\\'to_vader\\'].apply(vader_analitics)\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Создадим новые признаки - копии существующих и с ними будем работать\n",
    "hotels_t[['positive_rev_to_vader', 'negative_rev_to_vader']] = \\\n",
    "    hotels_t[['positive_review', 'negative_review']].copy()\n",
    "\n",
    "# Функция для подмены позитивных слов в негативных отзывах\n",
    "def negative_turnover(elem):\n",
    "    neg_to_pos_list = ['leaving', 'no negative', 'nothing']\n",
    "    for word in neg_to_pos_list:\n",
    "        elem = elem.lower()\n",
    "        elem = elem.replace(f'{word}', 'positive')\n",
    "    return elem\n",
    "\n",
    "# Функция для подмены негативных слов в позитивных отзывах\n",
    "def positive_turnover(elem):\n",
    "    pos_to_neg_list = ['nothing', 'no positive']\n",
    "    for word in pos_to_neg_list:\n",
    "        elem = elem.lower().replace(f'{word}', 'negative')\n",
    "    return elem\n",
    "    \n",
    "# Применений функций к признакам\n",
    "hotels_t['negative_rev_to_vader'] = \\\n",
    "    hotels_t['negative_rev_to_vader'].apply(negative_turnover)\n",
    "\n",
    "\n",
    "hotels_t['positive_rev_to_vader'] = \\\n",
    "    hotels_t['positive_rev_to_vader'].apply(positive_turnover)\n",
    "\n",
    "# \"Склейка\" позитивного и негативного отзывов в единый (для извлечений compound)\n",
    "hotels_t['to_vader'] = \\\n",
    "    hotels_t['positive_rev_to_vader'] + hotels_t['negative_rev_to_vader'] \n",
    "\n",
    "# Функция для получения коэффициента общего значения \n",
    "# по словам суммарного отзыва\n",
    "def vader_analitics(review):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(review)\n",
    "    return ss['compound']\n",
    "\n",
    "# Создание нового признака \n",
    "hotels_t['vader_score'] = hotels_t['to_vader'].apply(vader_analitics)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Функция для получения коэффициента позитивного окраса \\n# по словам позитивного отзыва\\ndef vader_analitics_positive(review):\\n    sid = SentimentIntensityAnalyzer()\\n    ss = sid.polarity_scores(review)\\n    return ss['pos']\\n\\n# Создание нового признака \\nhotels_t['vader_score_pos'] = hotels_t['positive_rev_to_vader'].apply(vader_analitics_positive)\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Функция для получения коэффициента позитивного окраса \n",
    "# по словам позитивного отзыва\n",
    "def vader_analitics_positive(review):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(review)\n",
    "    return ss['pos']\n",
    "\n",
    "# Создание нового признака \n",
    "hotels_t['vader_score_pos'] = hotels_t['positive_rev_to_vader'].apply(vader_analitics_positive)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Функция для получения коэффициента негативного окраса \\n# по словам негативного отзыва\\ndef vader_analitics_negative(review):\\n    sid = SentimentIntensityAnalyzer()\\n    ss = sid.polarity_scores(review)\\n    return ss['neg']\\n\\n# Создание нового признака \\nhotels_t['vader_score_neg'] = hotels_t['negative_rev_to_vader'].apply(vader_analitics_negative)\\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Функция для получения коэффициента негативного окраса \n",
    "# по словам негативного отзыва\n",
    "def vader_analitics_negative(review):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(review)\n",
    "    return ss['neg']\n",
    "\n",
    "# Создание нового признака \n",
    "hotels_t['vader_score_neg'] = hotels_t['negative_rev_to_vader'].apply(vader_analitics_negative)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Список признаков к копированию \\n# (коэффциентов от работы метода SentimentIntensityAnalyzer)\\nverdered_feats_list = ['vader_score', 'vader_score_pos', 'vader_score_neg']\\n\\n# Выведем полученные значения \\n\\nvader_scores_t = hotels_t[verdered_feats_list].copy()\\nvader_scores_t.to_csv('data/vader_scores_t.csv', index=False)\\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Список признаков к копированию \n",
    "# (коэффциентов от работы метода SentimentIntensityAnalyzer)\n",
    "verdered_feats_list = ['vader_score', 'vader_score_pos', 'vader_score_neg']\n",
    "\n",
    "# Выведем полученные значения \n",
    "\n",
    "vader_scores_t = hotels_t[verdered_feats_list].copy()\n",
    "vader_scores_t.to_csv('data/vader_scores_t.csv', index=False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/1QOOTUIgujpAeo3vQumlzgqihWiYRHK2a/view?usp=drive_link'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "vader = pd.read_csv(url)\n",
    "\n",
    "hotels_t = pd.concat([hotels_t, vader], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим копии признаков, которые будем обрабатывать\n",
    "hotels_t['negative_review_copy'] = hotels_t['negative_review']\n",
    "hotels_t['positive_review_copy'] = hotels_t['positive_review']\n",
    "\n",
    "# Произведем удаление значений, не характеризующих негативный \n",
    "# или позитивный опыт\n",
    "hotels_t['negative_review_copy'] = \\\n",
    "    hotels_t['negative_review_copy'].apply(\n",
    "    lambda x: '' if (x.strip().lower() == 'leaving') |\n",
    "    (x.strip().lower() == 'no negative')\n",
    "    else x\n",
    "    )\n",
    "\n",
    "hotels_t['positive_review_copy'] = \\\n",
    "    hotels_t['positive_review_copy'].apply(\n",
    "    lambda x: '' if (x.strip().lower() == 'no positive') else x\n",
    "    )\n",
    "    \n",
    "# Список частиц, не участвующих в подсчете слов, так же, \n",
    "# сюда добавим пустое значение, оно местами присутствует в DF, \n",
    "# и, вероятно, в оригинальном датасете и давало лишние числа\n",
    "article_list = ['the', 'a', 'an', 'and', 'of', 'in', 'on', 'or', '']\n",
    "\n",
    "# Функция подсчета слов\n",
    "def word_counter(rev):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    rev = rev.strip().lower()\n",
    "    rev_list = rev.split(' ')\n",
    "    \n",
    "    for elem in rev_list:\n",
    "        if elem not in article_list:\n",
    "            result.append(elem)\n",
    "    \n",
    "    return len(result)\n",
    "\n",
    "# Создадим новые признаки количества слов, применив функцию\n",
    "hotels_t['negative_word_true'] = \\\n",
    "    hotels_t['negative_review_copy'].apply(word_counter)\n",
    "\n",
    "hotels_t['positive_word_true'] = \\\n",
    "    hotels_t['positive_review_copy'].apply(word_counter)\n",
    "\n",
    "# Функция расчета соотношения позитивных слов к негативным\n",
    "def ratio_calc(negative, positive):\n",
    "    try:\n",
    "        result = positive / negative\n",
    "    except:\n",
    "        result = (positive + 1) / (negative + 1)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Создаем новый признак соотношения слов, применив функцию\n",
    "hotels_t['pos_neg_ratio'] = hotels_t.apply(\n",
    "    lambda x: ratio_calc(x.negative_word_true,\n",
    "                         x.positive_word_true),\n",
    "    axis = 1\n",
    "    )\n",
    "\n",
    "# Список признаков на удаление\n",
    "list_to_drop_revs = ['negative_review_copy', 'positive_review_copy', \n",
    "                'negative_review', 'positive_review', \n",
    "                'review_total_negative_word_counts', \n",
    "                'review_total_positive_word_counts'\n",
    "                ]\n",
    "\n",
    "# Удаление признаков\n",
    "hotels_t = hotels_t.drop(\n",
    "    columns = list_to_drop_revs, axis=1\n",
    "    )\n",
    "\n",
    "# Переименуем колонки новых признаков\n",
    "hotels_t = hotels_t.rename(columns={\n",
    "    'negative_word_true' : 'negative_word_qnt',\n",
    "    'positive_word_true' : 'positive_word_qnt'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для очистки значений признака тагов от лишних элементов \n",
    "def tag_renewal(tag):\n",
    "\n",
    "    tag = tag.split(',')\n",
    "\n",
    "    # Формирование списка из очищенных тагов\n",
    "    new_tag = list(map(\n",
    "        lambda x: ( re.search( \"' (.*) '\", str(x) ) ).group(1).lower(), \n",
    "        tag\n",
    "        ))\n",
    "   \n",
    "    # Возврат обновленного очищенного списка\n",
    "    return new_tag\n",
    "\n",
    "# Создаем новый признак, очищенную копию прошлого признака \n",
    "hotels_t['new_tags'] = hotels_t['tags'].apply(tag_renewal)\n",
    "\n",
    "# Удалим отработанный признак\n",
    "hotels_t = hotels_t.drop(columns=['tags'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ряд типовых функция для обработки признака с возвратом бинарного значения\n",
    "def is_mobile(feature):\n",
    "    if re.findall('mobile device', str(feature)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_leisure(feature):\n",
    "    if re.findall('leisure trip', str(feature)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_business(feature):\n",
    "    if re.findall('business trip', str(feature)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Создание новых признаков с применением написанных функций\n",
    "hotels_t['mobile_submit'] = hotels_t['new_tags'].apply(is_mobile)\n",
    "hotels_t['leisure trip'] = hotels_t['new_tags'].apply(is_leisure)\n",
    "hotels_t['business trip'] = hotels_t['new_tags'].apply(is_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка в части категориальных признаков будет связана с индексами \n",
    "# элементов списка - значения признака new_tags, поэтому, \n",
    "# необходимо сделать проверку на количество элементов списка, для \n",
    "# этого создадим вспомогательный признак - количество тагов .\n",
    "hotels_t['tags_qnt'] = hotels_t['new_tags'].apply(\n",
    "    lambda x: len(x)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для извлечения описание типа номера \n",
    "# (Применяем к тем строкам, где высока вероятность соблюдения порядка\n",
    "# в тэгах, задаемся количеством тэгов больше или равно 4)\n",
    "def room_extract(qnt, tag):\n",
    "    if qnt >= 4:\n",
    "        return tag[2]\n",
    "    else: \n",
    "        return 'Unknown'\n",
    "\n",
    "# Применим функцию к DF для создания временного признака с типом номера\n",
    "hotels_t['room_type_temp'] = hotels_t.apply(\n",
    "    lambda x: room_extract(x.tags_qnt, x.new_tags), axis = 1\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На основе выбранных ключевых слов - функция для \n",
    "# определения категории номера \n",
    "def room_type(tags):\n",
    "    tags = str(tags).lower()\n",
    "    \n",
    "    if re.findall('superior', tags) or \\\n",
    "        re.findall('deluxe', tags) or \\\n",
    "            re.findall('queen room', tags) or \\\n",
    "                re.findall('club', tags):\n",
    "                    return 'superior'\n",
    "    if re.findall('suite', tags):\n",
    "        return 'suite'\n",
    "    else:\n",
    "        return 'standart'\n",
    "\n",
    "# Создаем новый признак типа номера (он уже будет постоянный)\n",
    "hotels_t['room_type'] = hotels_t['new_tags'].apply(room_type)\n",
    "\n",
    "# Удалим временный признак типа номера \n",
    "hotels_t = hotels_t.drop(columns = ['room_type_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аналогичный подход к обработке признака состава путешественников\n",
    "\n",
    "# Функция для извлечения описание состава путешественников \n",
    "# (Применяем к тем строкам, где высока вероятность соблюдения порядка\n",
    "# в тэгах, задаемся количеством тэгов больше или равно 4)\n",
    "def travelers_extract(qnt, tag):\n",
    "    if qnt >= 4:\n",
    "        return tag[1]\n",
    "    else: \n",
    "        return 'Unknown'\n",
    "\n",
    "# Применим функцию к DF для создания временного признака с типом номера\n",
    "hotels_t['travelers_temp'] = hotels_t.apply(\n",
    "    lambda x: travelers_extract(x.tags_qnt, x.new_tags), axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На основе выбранных ключевых слов - функция для \n",
    "# определения категории номера \n",
    "def travelers_type(tags):\n",
    "    tags = str(tags).lower()\n",
    "    \n",
    "    if re.findall('solo', tags):\n",
    "        return 'solo'\n",
    "    if re.findall('group', tags) or \\\n",
    "        re.findall('friend', tags):\n",
    "        return 'friends'\n",
    "    if re.findall('family', tags) or \\\n",
    "        re.findall('child', tags):\n",
    "        return 'family'\n",
    "    if re.findall('couple', tags):\n",
    "        return 'couple'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Создаем новый признак типа номера (он уже будет постоянный)\n",
    "hotels_t['traveler_type'] = hotels_t['new_tags'].apply(travelers_type)\n",
    "\n",
    "# Удалим временный признак типа номера \n",
    "hotels_t = hotels_t.drop(columns = ['travelers_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для поиска значений количества ночей\n",
    "def nights_calc(tags):\n",
    "    try:\n",
    "        tags = str(tags).lower()\n",
    "        result = re.search('stayed (.*) night', tags).group(1)\n",
    "        return int(result)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "hotels_t['nights_qnt'] = hotels_t['new_tags'].apply(nights_calc)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество пропусков не вилико, заполним их медианой по признаку\n",
    "hotels_t['nights_qnt'] = hotels_t['nights_qnt'].fillna(\n",
    "    hotels_t['nights_qnt'].median()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_t['nights_qnt'] = hotels_t['nights_qnt'].apply(\n",
    "    lambda x: 10 if x >= 10 else x\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_t = hotels_t.drop(columns = ['new_tags', 'tags_qnt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_t_encode = hotels_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список признаков для кодирования\n",
    "columns_to_encode = ['days_since_review', \n",
    "                     'country',\n",
    "                     'review_season', \n",
    "                     'traveler_type'\n",
    "                     ]\n",
    "\n",
    "# Циклом произведем кодирование признаков\n",
    "for feature in columns_to_encode:\n",
    "    encoder = ce.OneHotEncoder(cols=[f'{feature}'], use_cat_names=True)\n",
    "    type_bin = encoder.fit_transform(hotels_t_encode[f'{feature}'])\n",
    "    hotels_t_encode = pd.concat([hotels_t_encode, type_bin], axis=1)\n",
    "\n",
    "room_type_dict = {\n",
    "    'standart' : 1,\n",
    "    'superior' : 2,\n",
    "    'suite' : 3\n",
    "    }\n",
    "\n",
    "# Порядковое кодирование признака room_type\n",
    "ord_encoder = ce.OrdinalEncoder(mapping=[{\n",
    "    'col': 'room_type',\n",
    "    'mapping': room_type_dict\n",
    "    }])\n",
    "\n",
    "data_bin = ord_encoder.fit_transform(hotels_t_encode['room_type'])\n",
    "\n",
    "hotels_t_encode = pd.concat(\n",
    "    # Сразу \"по месту\" произведем удаление исходного признака room_type\n",
    "    [hotels_t_encode.drop(columns=['room_type'], axis=1), data_bin], \n",
    "    axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем удаление признаков, которые уже закодированы\n",
    "hotels_t_encode = hotels_t_encode.drop(\n",
    "    columns = columns_to_encode,\n",
    "    axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем стандартизатор StandardScaler\n",
    "r_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# трансформируем исходный датасет (закодированный)\n",
    "hotels_t_encode_norm = r_scaler.fit_transform(hotels_t_encode)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм\n",
    "hotels_t_encode_norm = pd.DataFrame(\n",
    "    hotels_t_encode_norm, \n",
    "    columns = list(hotels_t_encode.columns)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем стандартизатор StandardScaler\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# трансформируем исходный датасет\n",
    "hotels_t_encode_norm_stnd = s_scaler.fit_transform(hotels_t_encode_norm)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "hotels_t_encode_norm_stnd = pd.DataFrame(\n",
    "    hotels_t_encode_norm_stnd, \n",
    "    columns = list(hotels_t_encode.columns)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем стандартизатор StandardScaler\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# трансформируем исходный датасет\n",
    "hotels_t_encode_norm_stnd = s_scaler.fit_transform(hotels_t_encode_norm)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "hotels_t_encode_norm_stnd = pd.DataFrame(\n",
    "    hotels_t_encode_norm_stnd, \n",
    "    columns = list(hotels_t_encode.columns)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hotels_t_encode_norm_stnd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим данные на прогнозируемые значения и остальные\n",
    "X = df.drop(['reviewer_score'], axis = 1)  \n",
    "y = df['reviewer_score'] \n",
    "\n",
    "# Метод для деления данных на категории\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# 4 категории \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "# инструмент для создания и обучения модели  \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "# инструменты для оценки точности модели \n",
    "from sklearn import metrics \n",
    "\n",
    "# модель\n",
    "regr = RandomForestRegressor(n_estimators=100)  \n",
    "    \n",
    "# Обучаем модель на тестовом наборе данных  \n",
    "regr.fit(X_train, y_train)  \n",
    "    \n",
    "# Используем обученную модель для предсказания рейтинга отелей в тестовой выборке.  \n",
    "# Предсказанные значения записываем в переменную y_pred  \n",
    "y_pred = regr.predict(X_test)  \n",
    "\n",
    "# Коэфициент оценки эффективности\n",
    "mape = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print('MAPE:', mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://drive.google.com/uc?id=1GgW9N_C6fqoXUD_P4pdIUQPcQg-ulKyd'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/file/d/1GgW9N_C6fqoXUD_P4pdIUQPcQg-ulKyd/view?usp=drive_link'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
