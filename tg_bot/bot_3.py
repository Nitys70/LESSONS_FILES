import logging
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

# üîê –¢–≤–æ–∏ –∫–ª—é—á–∏
TELEGRAM_BOT_TOKEN = "fdas"
OPENAI_API_KEY = "vr"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ API –∫–ª—é—á–∞ OpenAI
openai.api_key = OPENAI_API_KEY

# ‚ú® –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_message}")

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": user_message}],
            max_tokens=1000,
            temperature=0.7,
        )
        reply = response.choices[0].message.content.strip()
        print(f"–û—Ç–≤–µ—Ç –æ—Ç OpenAI: {reply}")
        await update.message.reply_text(reply)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")  # üëà –ø–æ–∫–∞–∂–µ—Ç —Ç–æ—á–Ω—É—é –ø—Ä–∏—á–∏–Ω—É
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT.")

# /start –∫–æ–º–∞–Ω–¥–∞
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å, –∏ —è –æ—Ç–≤–µ—á—É –∫–∞–∫ ChatGPT ü§ñ")

# üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    app.run_polling()

if __name__ == "__main__":
    main()
